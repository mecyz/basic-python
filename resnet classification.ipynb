{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMlUBZxTl2UsVz2mvvgLuWI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"UksVwHz6t-7G","executionInfo":{"status":"error","timestamp":1719066516733,"user_tz":-330,"elapsed":126381,"user":{"displayName":"Ayush Goyal","userId":"12629648698287542154"}},"outputId":"c117d6aa-2257-422e-9fee-3a291758090c"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0c8e037cda7b>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Define paths to your dataset folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import os\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Define paths to your dataset folders\n","train_data_dir = '/content/drive/My Drive/Train'\n","\n","# Image dimensions expected by ResNet50\n","img_height, img_width = 100, 100\n","num_classes = 3  # Number of classes (assuming 3 classes: SUV, Truck, Bus)\n","\n","# Use ImageDataGenerator for data augmentation and preprocessing\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2  # 20% validation split\n",")\n","\n","# Generate batches of augmented data from the directories\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training'  # set as training data\n",")\n","\n","# Validation data generator\n","valid_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='validation'  # set as validation data\n",")\n","\n","# Load pre-trained ResNet50 model without the top classification layer\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n","\n","# Freeze all layers in the base ResNet50 model\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Add a global average pooling layer\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","\n","# Add a fully connected layer with 256 hidden units and ReLU activation\n","x = Dense(256, activation='relu')(x)\n","\n","# Add a final softmax layer for classification\n","predictions = Dense(num_classes, activation='softmax')(x)\n","\n","# Combine the base model and custom layers\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Print model summary\n","model.summary()\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n","    epochs=1,\n","    validation_data=valid_generator,\n","    validation_steps=valid_generator.samples // valid_generator.batch_size\n",")\n","\n","# Evaluate the model on a random image from the dataset\n","def evaluate_random_image(model, data_dir, img_height, img_width):\n","    # Get list of all classes\n","    classes = sorted(os.listdir(data_dir))\n","\n","    # Pick a random class\n","    random_class = random.choice(classes)\n","    class_dir = os.path.join(data_dir, random_class)\n","\n","    # Get list of all images in the class directory\n","    all_images = os.listdir(class_dir)\n","\n","    # Pick a random image from the class\n","    random_image = random.choice(all_images)\n","    img_path = os.path.join(class_dir, random_image)\n","\n","    # Load and preprocess the image\n","    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(img_height, img_width))\n","    img_array = tf.keras.preprocessing.image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)  # expand dimensions to fit batch size\n","    img_array = img_array / 255.  # rescale to [0,1]\n","\n","    # Predict class probabilities\n","    predictions = model.predict(img_array)\n","    predicted_class = np.argmax(predictions)\n","\n","    # Display the image and predicted class\n","    plt.imshow(img)\n","    plt.axis('off')\n","    plt.title(f'Actual: {random_class}, Predicted: {classes[predicted_class]}')\n","    plt.show()\n","\n","# Evaluate on a random image\n","evaluate_random_image(model, train_data_dir, img_height, img_width)\n"]}]}